\chapter{Empirical Literature}\label{ch:3}

In this chapter, we review empirical evidence for the models discussed in Chapter~\ref{ch:2}. To some extent, the distinction between the theoretical and empirical literture is artificial: models of wage differentials and technology are difficult to separate from the empirical regularities that they describe. Nonetheless, in this section, we discuss four broad classes of studies.

First, we briefly discuss results from demographic studies of the work force. These `model-free' studies are important because they provide the empirical regularities that models are intended to explain. Second, we look at estimates of skill changes, based on classification schemes and other measures. Third, we discuss estimates of neoclassical models of the labor force, in which model parameters are calibrated to mean values derived from survey and aggregate data. Finally, we review some examples of decomposition-type studies, in which non-parameteric and semi-parametric evidence for wage-setting models are drawn from wage distribution.

There is a large body of evidence for upskilling and polarization in foreign labor markets; indeed this evidence prompted much of the research into skill-biased technical change. We touch briefly on these studies, but where possible, our focus here is on Australian research. Somewhat surprisingly, since one of the key explanations for SBTC includes globalization and the worldwide proliferation of new technology, the evidence for SBTC in Australia is does not exactly match the US and European experience. However, many studies have confirmed a growing demand for skilled labor, as well as an associated growth in its supply.

\section{Occupational Changes in the 1980s}

Beginning in the 1980s, a divergence between the rental rates of skilled an unskilled labor began to emerge in the US. \citet{Acemoglu2011} report that the `skill premium' paid to college-educated workers remained relatively steady between 1964 and 1980, oscillating in the range of between 48 and 58 per cent, if other factors are held constant constant. However, from 1980, this premium increased steadily, far outpacing the growth rates of other types of labor, dramatically increasing wage inequality between income groups. This trend was documented using CPS microdata by \citet{Karoly1992} and \citet{Katz1989}, among others, using reported educational attainment to identify individuals into groups.\footnote{The US experience was not universal: \citet{Katz1989} found, for example, that Japanese wage differentials had not followed the same pattern.} These studies also identified an intensification of the proportion of workers in the US with tertiary qualifications. To some extent, there were factors unrelated to the work force that could be explain this jump in educational attainment: in the 1970s, students who continued college study were exempt from service in Vietname, and returning veterans were granted scholarships via the G.I. bill \citet{Acemoglu2011}. Nonetheless, the two labor market trends emerging from this literature were a continual `up-skilling' of the workforce since the 1980s, and a steady increase in the `college premium', the average premium paid to workers who had attained college degrees or higher.

\subsection{Upskilling in Australia}

%We will take as a point of departure the standard model for analyzing skill-based technical change (SBTC). This model, dubbed the `canonical' model by \citet{Acemoglu2011} and which has sparked a voluminous literature, has enjoyed considerable empirical success explaining rising wages for high-skill managerial and professional jobs in the United States and Europe \citep{Katz1992}. Since the canonical model includes \emph{factor-augmenting} capital, it predicts a uniform skill upgrading of the work force at all education levels \citep{Levy2003}. Skill upgrading has been confirmed by a number of authors, both in Australia \citep{Esposto2012, Wooden2000, Cully1999} and overseas \citep{Autor2008}. 

Occupational classification schemes such as the ASCO \citep{Castles1986}, and the ANZSCO \citep{Trewin2006} include a numeric skill ranking for each occupation. Although the use of these statistics has been somewhat controversial\footnote{\citet{Cully1999} argues their use originates from the need to place employees in a social class, rather than analyze the skill intensity of the work}, they do provide simple categories by which descriptive analysis of the skill distribution can be performed. 

\citet{Cully1999} divides employment data into five skill levels, and analyzes changes in the number of jobs at each category between 1986 and 1997. He finds that, over this period, there was growth in the high- and low-skilled jobs, but that the number of jobs in the middle categories declined, lending some support to the polarization hypothesis. However, in line with international evidence, the dominant pattern in the data is growth in high-skilled jobs, or `up-skilling.' A conclusion is reached by \cite{Wooden2000}, who expands Cully's methodology to also consider growth in terms of hours worked.

The college premium is linked to the supply of labor by \cite{Card2001}. They note that the rising college premium measured in the data is attributable almost entirely to younger cohorts of workers, and especially for men in their early thirties. They argue that the driving force behind the rising college premium is a slowdown in the pace of educational attainment, relative to the demand for labor.

Australian labor market definitely increasing in (1) skills, (2) knowledge intensity. \citet{Esposto2012} \citet{Esposto2011} \cite{Borland1999}

% \citet{Autor2009} analyze an economy where rising demand for service occupations 

\subsection{Direct Measures of Technical Change and Skill Premia}

One way to determine whether technology is skill-biased is to directly analyze the properties and wage distributions of jobs that use new technologies. One advantage of this type of study, is the absence of an economic model---so the results are less susceptible to specification biases. To support the claim of SBTC, there are two claims that we want to see verified from sample surveys: first, that technology adoption is growing, and that the nature of work changes as a result (existence of technical change). Second, we expect to see that this technology impacts primarily on those with high skills (existence of skill bias).

Qualitiative research on the nature of computerization strongly supports the claim that technology dramatically changes workplaces. Evidence from the US Current Population Survey confirms that, during the 1980s and 1990s, there was indeed an increased incidence of computer use in the workplace. Between 1984 and 1997, the data show that the the proportion of individuals using computers at work increased from 24\% to 51\% \cite{Friedberg2003}. Furthermore, evidence from the 1990s shows that the introduction of new technology results in a substantial rearranging of work patterns. \citet{Levy1996} studied the application of new technology to automate tasks in a financial services firm. He found that, although technology process simplified many of the processes, those that were not automated became more complicated. Similarly, \citet{Autor2002} studied the introduction of digital check imaging in a large bank, and found that, while many `routine' tasks were easily automated, substantial changes occurred in those tasks that could not be performed by machiens. \citet{Bresnahan2002} offers evidence that the introduction of computers into workplaces often incurs significant adjustment costs, including re-training, re-organization, and so on.

A limited number of surveys have been conducted in Australia. \citet{Borland2004} employs a cross-sectional survey of Australian workers, the 1993 ABS Training and Education Experience Survey (TEES). This survey included detail of workers' skills and depth of computer knowledge, as well as interval-censored earnings information. Using interval regression techniques, Borland regressed a number of human capital, experience and job characteristic variables against income, worker characteristics and proxies for skills, as well as a categorical variable concerning computer use and experience. 

Without controls, the return to computer use in 1993 is estimated at 18 per cent of earnings; however, once controls are included, this effect reduces to about 8 per cent. One problem with this type of study is that, since computer use is associated with high-skilled work, individuals' unobserved ability is likely to be correlated with computer use. Despite the inclusion of proxies for individual skill and ability, this means that the return to computer use cannot be exactly identified. Nonetheless, this study does strongly suggest the presence of a skill premium in the Australian labor market.

\section{Rising College Premia}

Recall from Section~\ref{sec:canonical} that, as the high-skilled technology increases, the canonical model of SBTC predicts a rising premium to be paid to high-skill workers. Indeed, evidence from the United States and Europe support this claim.

\citet{Katz1992} estimate a version of the skill premium, as described in \eqref{eq:omega}. To do so, they assume an exponential functional form for the evolution of the technology ratio, $A_H/A_L$, over time,
$$  (A_H/A_L)(t) = A_{0}e^{A_1t}, $$
which when substituted into \eqref{eq:omega} yields a regression model of the following form:
$$ \log \omega_t = \frac{\sigma - 1}{\sigma}\beta_0 + \frac{\sigma-1}{\sigma}\beta_1t - \beta_2\log\left(\frac{H_t}{L_t}\right) + \epsilon_t, $$
where $\log(H/L)$ is the log wage share ratio. Using data from 1963 to 1987, they estimate
$$
  \log \omega_t = \kappa + \underset{\scriptsize (0.007)}{0.033} t - \underset{\scriptsize (0.150)}{0.709}\left( \frac{H_t}{L_t} \right),
$$
where $\kappa$ is a constant. This model implies a college premium rising at a rate of approximately 3.3 per cent annually.

As \citet{Acemoglu2011} point out, this model predicts the rise in the college premium over the following decade reasonably well, although it does under-predict the true level of between-group inequality somewhat from 2002 onwards.

\subsection{College Premia in Australia}

Somewhat surprisingly, college premia are not readily apparent in the Australian data. \citet{Barnes2002} analyze household survey data, and use educational attainment as a proxy for skill. They find that, over the 1980s and 1990s, growth in the demand for high-skilled far outpaced that of low-skilled workers. In the 1980s, the demand for skilled employment grew at a rate of 4.7 per cent per year (against 0.5 per cent annually for unskilled unmployment), and in the 1990s, the growth rates were 3 per cent and 0.8 per cent, respectively.

In contrast to the American and European experience, \citet{Barnes2002} find no evidence of a skill premium. Using industry measures as proxies for demand, the authors attempt to decompose the differences between relative demand and supply for each type of labor, and find negligible discrepancies. They conclude that the lack of a college premium  is due to the supply of both types of labor expanding at the same rate their respective demands, creating no scarcity premium in the labor market.

No college premium was found by \citet{Coelli2009}, who follows a similar procedure to \citet{Katz1992}. He employs both income survey microdata and census samples to estimate the premium paid to university graduates, in excess of those without university degrees, between 1981 and 2004. Like \citet{Barnes2002}, Coelli finds that, that although a university premium exists, it is not rising, as it is in the United States and Europe.

Coelli suggests two novel interpretations for this finding. First, he notes differences between the Australian and US system of tertiary qualifications. In the US, bachelor degrees take four years to attain, but in Australia, three-year degrees are the norm. He also points out that changes to higher education funding arrangements in the 1990s have broadened the scope of teritary degrees tremendously, so that many degrees now cover skills that would previously have been taught at technical colleges such as TAFE.

\subsection{Rising Skilled Labor Share}

Both the `canonical' model and the Ricardian models of occupational choice discussed in Chapter~\ref{ch:2} make predictions about the proportion of skilled and unskilled labor employed, in the presence of SBTC. 

Under the canonial model, the proportion of high-skilled labor employed should increase in the presence of SBTC. Using industry-level data between 1978 and 2000, \citet{DeLaine2001} analyze the changes in shares of skilled and unskilled labor, identified by educational attainment, at the industry level. They find that both the total wage bill and share of employment of skilled workers has increased dramatically, across all industries, in Australia over this period.

They further test whether technology investment or technology use indexes can explain this evolution. To do so, they employ a variety of functional forms, including CES production function and a flexible (translog) model to estimate changes in the shares of high-skill labor, as a function of R\&D spending, capital growth and a technology index. 

The manufacturing industry, when entered alone, shows a strong relationship between the share of skilled workers and technological change. However, the authors find that this relationship is weaker for other industries. \citet{DeLaine2001} find that the relationship strengthens in the 1980s, and posit that this period of extensive microeconomic reform allowed firms greater flexibility to adopt new technologies requiring more highly skilled work force.


Using cointegration techniques, \citet{Gaston2009} incorporate \citet{Leigh2005}'s income tax data in a time series model of the relationship between the Gini coefficient and macroeconomic variables, including the terms of trade, investment in ICT infrastructure, the unionisation rate, and indexes of social and economic globalisation. As well as other globalization indexes, they find that technology investment, interpreted as a proxy for SBTC, Granger (non-)causes increases in inequality, measured as the Gini coefficient.


\subsection{Test of Changing Wage Shares}



Using measures of the tasks involved in various occupations derived from the Dictionary of Occupational Titles, a manual compiled by the US Department of Labor describing the skill and activity content of occupations, as well as industry-level measures of wages and employment by occupation, \citet{Levy2003} show that this model explains a considerable proportion of the dispersion of wages in the United States between 1960 and 1998, computerization led to a substitution in the observed levels of employment, away from routine tasks and toward cognitive tasks. Likewise, \citet{Goos2007} show a similar trend in the United Kingdom: between 1975 and 2003, they find a increase in the number of ``lovely'' (high-skill, high-wage) jobs and ``lousy'' (low-wage, low-skill) jobs, but a relative decrease in the number of ``middling'' jobs. In a subsequent paper, a similar pattern was found for Continental Europe \citep{Goos2009}.


\section{Decomposition Methods}

Empirically, we take as our point of departure the analysis of the US occupational wage structure performed by \citet{Fortin2011}, who build on the work of \citet{Oaxaca1973} and \citet{Juhn1993} to decompose the impact of demographic variables and occupational tasks on the wage structure. Following \citet{Autor2012} and \citet{Fortin2011}, we assume that workers self-select into occupations based on comparative advantage, in a model reminiscent of Roy's (\citeyear{Roy1951}) model of occupational choice.

In the previous two chapters, we assumed little about the functional relationship between specific skills and wages. Decomposition methods are especially powerful because they are able to extract relatively rich information from the data. This strength comes at the price of relatively strong assumptions imposed on the data in order to guarantee parameter identification; the limitations these assumptions bring are shared by all decomposition methods. These assumptions are discussed in detail in section~\ref{sec:id}, and mostly stem from the fact that decompositions provide only `shallow' analyses of economic phenomena, and are not able to model `deep,' structural properties of the labour market. The most important of these restrictions, and possibly the least palatable, is the following. Despite motivating our model with Roy's model, a general-equilibrium framework, the empirical analysis presented below assumes that general equilibrium effects are completely dominated by first-order effects, so that market outcomes in each occupation's labour market depends only on the supply and demand for skills in that occupation.\footnote{Within a general equilibrium framework, this assumption is equivalent to the assumption of diagonal dominance \citep[p.233]{Arrow1971}.} This assumption is questionable: it is quite likely, for example, that a collapse in the demand for labour in one occupation, would cause some workers to change their occupational affiliations, triggering a shift in the supply of labour in other occupations. Nonetheless, this and other assumptions we employ below are standard in the inequality literature \citep[p.1]{Fortin2011}. These limitations will be discussed in greater detail, below.


The next step in the analysis is to decompose changes in the log wage distribution according, according to task index measures. The decomposition methods upon which this study is based were first considered by \citet{Oaxaca1973} and \citet{Blinder1973}. 

Consider some outcome variable, such as an average log wage, that differs for two disjoint groups. Oaxaca, for instance, considered the difference in mean wages paid to men and women. Let the difference in the mean wage for men and women be $\Delta$:
\begin{equation} \Delta = E[\ln y_m] - E[\ln y_f]. \label{eq:odec} \end{equation}
If $\Delta$ is nonzero, this might be explainable by (a) factors arising from different human capital endowments in each group, (b) factors arising purely from the fact of group membership, or (c) both. The goal of the Oaxaca-Blinder (OB) decomposition is to divide this difference into two components: the component explainable by human capital factors (the endowment effect), and a structural component attributable only to group membership.

To determine the influence of sex on the mean of the wage distribution, Oaxaca considered two separate regression models, one for each sex. Each vector $X_i$ of covariates included demographic and human capital variables such as years of education, work experience and age:
$$  \ln y_{g,i} = \ve{X}_{g,i}'\vbeta_g + \epsilon_{g,i} \quad \text{where}\ g=M,F. $$
Then, taking expectations of both sides and substituting into \eqref{eq:odec}, the difference of expected log wages can be decomposed as,
\begin{align}
  \Delta_O &= E[X_m]'\vbeta_m -  E[X_f]'\vbeta_f \notag \\
  &= \underbrace{E[X_m]'(\vbeta_m - \vbeta_f)}_{\Delta_S} + \underbrace{(E[X_m]'-E[X_f]')\vbeta_f}_{\Delta_X}. \label{eq:odecomp}
\end{align}
The second term of this decomposition, $\Delta_X$, is the difference in mean log wages that can be explained by human capital factors (the `endowments effect'). The other term, $\Delta_S$, represents the `structural' difference in wages between the two groups. In the case where the wages of males and females are being considered, this term can be interpreted as the sex discrimination differential. The parameters in \eqref{eq:odecomp} are computed at their means to determine the difference $E[X_m]'(\vbeta_m - \vbeta_f)$ attributable to discrimination, in the mean log wage.

In the study at hand, the object of interest is the distribution of wages, rather than differences in the conditional mean, and the two groups of interest are not gender groups, but rather two different time periods, corresponding to periods when the Survey of Income and Housing was conducted: 1981-2 and 2009-10. For simplicity, we refer to these time periods as $T=0$ and $T=1$, respectively. Instead of sex, in our case the explanatory variables of interest is a given by vector of task content indexes for each occupation.  

% *****
Unlike Oaxaca, we must make one additional (and somewhat heroic) assumption, which we call {\em job uniformity}. In Oaxaca's study, he was able to take for granted that the meaning of the explanatory variables was invariant for both groups. for which the difference between maleness and femaleness can be assumed to be unfiorm over the entire period. The procedure for constructing these indexes is described in the data appendix, Section~\ref{sec:onet}.

\subsection{Unconditional Quantile Regression}
One major shortcoming of the Oaxaca-Blinder decomposition is that only the conditional means of a wage distribution, $E(Y|X)$, and its counterfactual can be compared. Recall that, in the Roy model described above, changes in the profitability of any occupation should result in the more efficient individuals self-selecting out of an occupation. The mean of a wage distribution is a poor instrument for observing this phenomenon: rather, any polarisation effect will be observed in the overall {\em distribution} of wages, $F_Y$. Ideally, we would like to compute a decomposition similar to \eqref{eq:odecomp}, but which decomposes changes in the $\alpha$th quantile of the wage distribution, $q_\tau(F_Y)$. Such a decomposition was considered by \citet{Firpo2011}; it is their technique, as described in \citet{Firpo2009}, that we apply here.

Under our decomposition, the wage of an individual $i$ is observed in one of two periods, $T=0$ or $T=1$. Under the hypothesis of wage polarisation, we will assume that individuals are paid under two distinct wage structures: the pre-polarisation wage structure that has distribution $F_{Y_0}$ (when $T=0$) and the post-polarisation wage structure, $F_{Y_1}$ (when $T=1$). We wish to compute an overall change $\Delta^\tau$ in the quantile statistic, attributable to changes in work force composition $\Delta^\tau_X$ and changes in the wage structure, $\Delta^\tau_S$:
\begin{align}
  \Delta^\tau_O &= q_\tau(F_{Y_1|T=1}) - q_\tau(F_{Y_0|T=0}) \notag \\
  &= \underbrace{q_\tau(F_{Y_1|T=1}) -  q_\tau(F_{Y_0|T=1})}_{\Delta^\alpha_S} + \underbrace{q_\tau(F_{Y_0|T=1}) - q_\tau(F_{Y_0|T=0})}_{\Delta^\alpha_X} \label{eq:decomp}
\end{align}Notice that this decomposition depends on the availability of a hypothetical counterfactual distribution, $F_{Y_0|T=1}$, wherein the workers of period $1$ are paid according to the wage structure of period~$0$. Although such a distribution cannot be directly observed, \citet{Firpo2011} show that a consistent estimator of $F_{Y_0|T=1}$ can be found by re-weighting $F_{Y_0}$ to have the same distribution as $F_{Y_1}$.

\citet{Firpo2009} demonstrate that the aggregate decomposition, as described in \eqref{eq:decomp}, can be performed using an OLS regression on the recentered influence function of the distributional statistic in question. The recentered influence function is the usual influence function used in the analysis of robust estimators, `recentered' by adding back the value of the distributional statistic. In the case of the quantile function $q_\tau$, the RIF is given by,
$$ RIF(y; q_\tau) = q_\tau + IF(y; q_\tau) = q_\tau + \frac{q_\tau - \mathbf{1}\{y \leq q_\tau\}}{f_Y(q_\tau)}. $$

Then the estimated coefficient $\gamma^{q_\tau}_t$ of an OLS regression of $RIF(y_t; q_\tau)$ on $X$ is
\begin{align*} 
\gamma^{q_\tau}_t &= (E[X \cdot X' | T = t])^{-1} \cdot E[RIF(y_t; q_\tau) \cdot X | T = t]
\intertext{\citet{Firpo2009} show that the distributional statistics themselves can be written as expectations of the conditional RIF, since the expected value of the influence function is zero, and thus $E[RIF(y_t;q_\tau)]=q_\tau$.}
q_\tau(F_t) &= E_X[E[RIF(y_t; q_\tau) | X=x]] = E[X|T=t] \cdot \gamma^{q_\tau}_t
\intertext{And thus we can write \eqref{eq:decomp} in a similar form as \eqref{eq:odecomp},}
\Delta^\alpha_O &= \underbrace{E[X|T=1] \cdot (\gamma^{q_\tau}_1 - \gamma^{q_\tau}_0)}_{\Delta^\alpha_S} + \underbrace{(E[X|T=1] - E[X|T=0]) \cdot \gamma^{q_\tau}_0}_{\Delta^\alpha_X}.
\end{align*}
Under the `ignorability' assumption, discussed below, both of these components of the decomposition are identified.

\subsection{Data Requirements for RIF-Regression} \label{sec:id}

One condition required for RIF-regression is that the support of covariates $X$ is the same for both time periods. In other words, it should not be possible to unambiguously predict which time period an observation belongs to, simply by observing the value of its covariates. 
\begin{assumption}[Overlapping support] \label{ass:overlap}
  Let the support of wage setting factors in both periods $[X',\epsilon']'$ be $\mathcal{X}\times\mathcal{E}$. For all $[x',e']' \in \mathcal{X}\times\mathcal{E}$,  $0 < \Pr[T=0 | X=x, \epsilon=e] < 1$.
\end{assumption}
Importantly, Assumption~\ref{ass:overlap} means that the set of occupational titles in both periods must be the same, even though many new types of occupational titles have been created since 1981-2. Despite to the small sample size, the data are only available at a two-digit level of aggregation, so that none of the occupations listed in the ANZSIC were missing a counterpart from 1981-2. A correspondence was easily found between two-digit ANZSIC groups and 1981-2 occupations, which were available at the three-digit level.

Further, in order to identify the explained and unexplained effects of the covariates, we require that the error term $\epsilon$ has the same conditional distribution in both time periods. This is known as the {\em ignorability} assumption.
\begin{assumption}[Ignorability]
  For $T\in\{0,1\}$, let $(T, X, \epsilon)$ have a joint distribution. Then, for all $x\in \mathcal{X}$, $\epsilon$ is independent of $T$ given $X=x$.
\end{assumption}

The assumptions stated so far are both plausible, and sufficient for identifying the wage structure component ($\hat{\Delta}_S$) and endowment effect component ($\hat{\Delta}_X$) of the aggregate decomposition. While this aggregate decomposition is useful, even more useful would be the ability to separate out the components of $\Delta_X$ or $\Delta_S$ into the contributions of each independent variable, the so-called `detailed decomposition'. 

\citep[p.27]{Fortin2011} show that non-parametric estimates of the detailed decomposition require assumptions that cannot be maintained in this context. For example,the following independence condition, found in \citet{Matzkin2003}, must hold:
\begin{assumption}[Independence]\label{ass:indep}
  For $T\in\{0,1\}$, $X$ is uncorrelated with $\epsilon$ in time $T$.
\end{assumption}
Most decompositions of the determinants of wages, including this one, follow the Mincerean `human capital' approach, which suggests that the primary determinants of wages are investments in education and experience, which enhance productivity \citep{Mincer1962}. For that reason, these covariates are included in $X$ in this study. However, as is well-known, OLS regression estimates of Mincer-style wage equations tend to exhibit endogeneity bias, since observable characteristics (such as years of schooling) tend to be correlated with unobserved characteristics such as general ability or talent \citep{Card1999}. Consequently, any regression specification that omits an accurate measure of `ability' will exhibit endogeneity bias, since the omitted variable will cause explanatory variables such as schooling to be correlated with the error term. That is to say, that the independence property is violated.

However, the impracticality of Assumption~\ref{ass:indep} is avoided by the linear functional form imposed by Assumption~\ref{ass:linear} \citep[p.28]{Fortin2011}. Furthermore, the linear functional form assumption allows for heteroskedasticity. This this application, this is a useful property, since income variance increases with educational attainment.

\subsection{Re-weighting the counterfactual distribution}\label{sec:reweight}

\citet[p.19]{Firpo2011} point out that the RIF-regression described above is a local approximation that may not hold for large variations in covariates $X$. In particular, if the relationship between $Y$ and $X$ is nonlinear, then shifts in the distribution of $X$ may result in different estimates for $\gamma^{q_\tau}_t$ even if $Y$ is invariant. 

Unfortunately, in this application, changes in covariates between period $T=0$ and $T=1$ cannot be assumed to be small. ABS data show that there are considerable differences in the composition of the labour force between 1981-2 and 2009-10 \citep{LFSApr2013}. The average unemployment rate in 1981-2 similar to that of 2009-10 (6.1 per cent versus 5.7 per cent, respectively), but the period was marked by considerable demographic changes. Since the 1980s, women have entered the work force in far greater numbers, and overall labour force participation patterns have varied. Between 1981-2 and 2009-10, the average participation rate for men fell from 77.7 per cent to 72.3 per cent. For women, on the other hand, the participation rate rose from 44.8 per cent to 58.6 per cent. And, for both sexes, the rate of part-time employment has increased dramatically. Clearly, the covariate distributions at both time periods are not directly comparable.

In order to create a comparable counterfactual wage distribution, \citet{Firpo2011} suggest a hybrid approach, where the data in period $0$ are reweighted so that covariates in period $0$ match those in period $1$. Adopting the re-weighting procedure suggested by \citet{DiNardo1996}, they aim to create a counterfactual wage distribution $F_{Y_0}^C$ that exhibits the characteristics of period $0$, but with the wage structure of period $1$:
\begin{align*}
  F_{Y_0}^C &= \int F_{Y_0|X_0}(y|X) dF_{X_1}(X)
\intertext{We now re-write this equation as an integral over $F_{X_0}(X)$, by adding a reweighting factor $\Psi(X) = dF_{X_1}(X)/dF_{X_0}(X)$:}
  F_{Y_0} &= \int F_{Y_0|X_0}(y|X) \Psi(X)dF_{X_0}(X)
\end{align*}
\citet{Fortin2011} show that this re-weighting factor, which is the ratio of two marginal distribution functions, can be manipulated with an application of Bayes' rule to yield a ratio of two binary outcome models:
\begin{align*}
  \label{eq:wt}
  \Psi(X) &= \frac{\Pr(T=1|X)/\Pr(T=1)}{\Pr(T=0|X)/\Pr(T=0)},
\end{align*}
that re-weights the data in period $0$ to match the distribution of covariates observed in period~$1$. To implement this re-weighting function, the probability of $T$ being 1 or 0 can be modeled using a probit model, fit to the combined data sets, with $T$ as the response variable. % Probit model: help! How do I weight this?

Using re-weighted data, we can estimate the means of the counterfactual distribution, $\hat{\bar{X}}=\sum_{i|T=0}\hat{\Psi}(X_i) \cdot X_i$, and the coefficients $\hat{\gamma}_{01}^{q_\tau}$ by regressing $RIF(Y_0;q_\tau)$ with the new sample weights. We then rewrite the decomposition \eqref{eq:decomp} as the sum of two separate Oaxaca-Blinder decompositions. The first term, the wage structure effect, is decomposed into a composition effect $\hat{\Delta}^{q_\tau}_{S,p}$ and specification error, $\hat{\Delta}^{q_\tau}_{S,e}$. The second gives a similar decomposition for composition effect:
\begin{align}
  \hat{\Delta}^{q_\tau} &= (\hat{\Delta}^{q_\tau}_{S,p} + \hat{\Delta}^{q_\tau}_{S,e}) + (\hat{\Delta}^{q_\tau}_{X,p} + \hat{\Delta}^{q_\tau}_{X,e}) \notag \\
  &= \underbrace{\left( [\bar{X}_{01} - \bar{X}_0 ] \hat{\gamma}^{q_\tau}_{01} +
    \bar{X}_{01}[\hat{\gamma}_{01}^{q_\tau} - \hat{\gamma}_0^{q_\tau}] \right)}_{\hat{\Delta}^{q_\tau}_{S}} +
  \underbrace{\left( \bar{X}_{1}[\hat{\gamma}_{1}^{q_\tau} - \hat{\gamma}_{01}^{q_\tau}] + 
    [\bar{X}_{1} - \bar{X}_{01} ] \hat{\gamma}^{q_\tau}_{01}\right)}_{\hat{\Delta}^{q_\tau}_{X}}.
\end{align}

This decomposition can be performed on income surveys of repeated cross-sections of the same markets over time.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
