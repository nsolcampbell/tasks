\chapter{Empirical Literature}\label{ch:3}


New empirical evidence emerging at the end of the 1990s suggested a `hollowing out' of the skill spectrum: that while high- and low-skilled jobs were growing, middle-skilled jobs were in fact shrinking.

Non-routine tasks, on the other hand, may improve, rather than replace, the efficiency of human workers. Indeed, as \citet{Borland2004} found by studying the computer knowledge of a cross-section of Australian workers surveyed in 1992, computer knowledge accrues a skill premium of around 10\%.


\section{Empirical Evidence for SBTC}

The empirical literature, which provides strong evidence for the SBTC thesis in foreign labor markets, has somewhat mixed support in Australia. Although there is a wealth of analysis on occupational change in the Australian labor market, less work has been done analyzing skill premia: largely this is because the patterns visible in the US and European labor markets are not present in the Australian context. However, many studies have confirmed a growing demand for skilled labor, as well as an associated growth in its supply.

The first group of studies look at changes in the workers' distribution of `skills'. The majority of these studies are demographic in nature, and tend provide descriptive statistics of changes in occupations as reported in sample surveys. Skill information is generally derived from occupational classification schemes.

The following group of studies examines 

Cover decomposition approach in more detail in Chapter~\ref{ch:4}.

The theory of skill-biased technical change with skill-capital complementarity outlined above suggests that two regularities should be observed in the data. First, 

% Katz & Murphy: \log \omega = \frac{\sigma - 1}{\sigma}\beta_0 + \frac{\sigma-1}{\sigma}\beta_1 - \beta_2\log\left(\frac{H_t/L_t}\right)

% \citet{Autor2009} analyze an economy where rising demand for service occupations 


\subsection{Upskilling in Australia}

Starting in the 1980s, in the United States a divergence between the rental rates of skilled an unskilled labor began to emerge. \citet{Acemoglu2011} report that the `skill premium' paid to college-educated workers remained relatively steady between 1964 and 1980, oscillating in the range of between 48 and 58 per cent, holding other factors constant. However, from 1980, this premium increased steadily 

We will take as a point of departure the standard model for analyzing skill-based technical change (SBTC). This model, dubbed the `canonical' model by \citet{Acemoglu2011} and which has sparked a voluminous literature, has enjoyed considerable empirical success explaining rising wages for high-skill managerial and professional jobs in the United States and Europe \citep{Katz1992}. Since the canonical model includes \emph{factor-augmenting} capital, it predicts a uniform skill upgrading of the work force at all education levels \citep{Levy2003}. Skill upgrading has been confirmed by a number of authors, both in Australia \citep{Esposto2012, Wooden2000, Cully1999} and overseas \citep{Autor2008}. 

Australian labor market definitely increasing in (1) skills, (2) knowledge intensity. \citet{Esposto2012} \citet{Esposto2011}

\cite{Cully1999} % upskilling, but no skill bias for Australia

\cite{Barnes2002} % 1990s, skilled empt incr 3% py ... see p. XI

\cite{Wooden2000} % upskilling and some evidence of skill polarisation. consistent with international evidence

\cite{Card2001} % supply <-> college premium

\cite{Borland1999}
\cite{Borland2000}

\subsection{The Skill Premium}

Direct studies of occupations have found that technology use within a job does indeed carry a skill premium. \citet{Borland2004} 

\cite{Autor1998} % computers <-> labor market

\cite{Coelli2009}


% Using cointegration techniques, \citet{Gaston2009} incorporate \citet{Leigh2005}'s income tax data in a time series model of the relationship between the Gini coefficient and macroeconomic variables, including the terms of trade, investment in ICT infrastructure, the unionisation rate, and indexes of social and economic globalisation. As well as other globalization indexes, they find that technology investment, interpreted as a proxy for SBTC, Granger (non-)causes increases in inequality, measured as the Gini coefficient.


Using measures of the tasks involved in various occupations derived from the Dictionary of Occupational Titles, a manual compiled by the US Department of Labor describing the skill and activity content of occupations, as well as industry-level measures of wages and employment by occupation, \citet{Levy2003} show that this model explains a considerable proportion of the dispersion of wages in the United States between 1960 and 1998, computerization led to a substitution in the observed levels of employment, away from routine tasks and toward cognitive tasks. Likewise, \citet{Goos2007} show a similar trend in the United Kingdom: between 1975 and 2003, they find a increase in the number of ``lovely'' (high-skill, high-wage) jobs and ``lousy'' (low-wage, low-skill) jobs, but a relative decrease in the number of ``middling'' jobs. In a subsequent paper, a similar pattern was found for Continental Europe \citep{Goos2009}.




\section{Decomposition Methods}

Empirically, we take as our point of departure the analysis of the US occupational wage structure performed by \citet{Fortin2011}, who build on the work of \citet{Oaxaca1973} and \citet{Juhn1993} to decompose the impact of demographic variables and occupational tasks on the wage structure. Following \citet{Autor2012} and \citet{Fortin2011}, we assume that workers self-select into occupations based on comparative advantage, in a model reminiscent of Roy's (\citeyear{Roy1951}) model of occupational choice.

In the previous two chapters, we assumed little about the functional relationship between specific skills and wages. Decomposition methods are especially powerful because they are able to extract relatively rich information from the data. This strength comes at the price of relatively strong assumptions imposed on the data in order to guarantee parameter identification; the limitations these assumptions bring are shared by all decomposition methods. These assumptions are discussed in detail in section~\ref{sec:id}, and mostly stem from the fact that decompositions provide only `shallow' analyses of economic phenomena, and are not able to model `deep,' structural properties of the labour market. The most important of these restrictions, and possibly the least palatable, is the following. Despite motivating our model with Roy's model, a general-equilibrium framework, the empirical analysis presented below assumes that general equilibrium effects are completely dominated by first-order effects, so that market outcomes in each occupation's labour market depends only on the supply and demand for skills in that occupation.\footnote{Within a general equilibrium framework, this assumption is equivalent to the assumption of diagonal dominance \citep[p.233]{Arrow1971}.} This assumption is questionable: it is quite likely, for example, that a collapse in the demand for labour in one occupation, would cause some workers to change their occupational affiliations, triggering a shift in the supply of labour in other occupations. Nonetheless, this and other assumptions we employ below are standard in the inequality literature \citep[p.1]{Fortin2011}. These limitations will be discussed in greater detail, below.


The next step in the analysis is to decompose changes in the log wage distribution according, according to task index measures. The decomposition methods upon which this study is based were first considered by \citet{Oaxaca1973} and \citet{Blinder1973}. 

Consider some outcome variable, such as an average log wage, that differs for two disjoint groups. Oaxaca, for instance, considered the difference in mean wages paid to men and women. Let the difference in the mean wage for men and women be $\Delta$:
\begin{equation} \Delta = E[\ln y_m] - E[\ln y_f]. \label{eq:odec} \end{equation}
If $\Delta$ is nonzero, this might be explainable by (a) factors arising from different human capital endowments in each group, (b) factors arising purely from the fact of group membership, or (c) both. The goal of the Oaxaca-Blinder (OB) decomposition is to divide this difference into two components: the component explainable by human capital factors (the endowment effect), and a structural component attributable only to group membership.

To determine the influence of sex on the mean of the wage distribution, Oaxaca considered two separate regression models, one for each sex. Each vector $X_i$ of covariates included demographic and human capital variables such as years of education, work experience and age:
$$  \ln y_{g,i} = \ve{X}_{g,i}'\vbeta_g + \epsilon_{g,i} \quad \text{where}\ g=M,F. $$
Then, taking expectations of both sides and substituting into \eqref{eq:odec}, the difference of expected log wages can be decomposed as,
\begin{align}
  \Delta_O &= E[X_m]'\vbeta_m -  E[X_f]'\vbeta_f \notag \\
  &= \underbrace{E[X_m]'(\vbeta_m - \vbeta_f)}_{\Delta_S} + \underbrace{(E[X_m]'-E[X_f]')\vbeta_f}_{\Delta_X}. \label{eq:odecomp}
\end{align}
The second term of this decomposition, $\Delta_X$, is the difference in mean log wages that can be explained by human capital factors (the `endowments effect'). The other term, $\Delta_S$, represents the `structural' difference in wages between the two groups. In the case where the wages of males and females are being considered, this term can be interpreted as the sex discrimination differential. The parameters in \eqref{eq:odecomp} are computed at their means to determine the difference $E[X_m]'(\vbeta_m - \vbeta_f)$ attributable to discrimination, in the mean log wage.

In the study at hand, the object of interest is the distribution of wages, rather than differences in the conditional mean, and the two groups of interest are not gender groups, but rather two different time periods, corresponding to periods when the Survey of Income and Housing was conducted: 1981-2 and 2009-10. For simplicity, we refer to these time periods as $T=0$ and $T=1$, respectively. Instead of sex, in our case the explanatory variables of interest is a given by vector of task content indexes for each occupation.  

% *****
Unlike Oaxaca, we must make one additional (and somewhat heroic) assumption, which we call {\em job uniformity}. In Oaxaca's study, he was able to take for granted that the meaning of the explanatory variables was invariant for both groups. for which the difference between maleness and femaleness can be assumed to be unfiorm over the entire period. The procedure for constructing these indexes is described in the data appendix, Section~\ref{sec:onet}.

\subsection{Unconditional Quantile Regression}
One major shortcoming of the Oaxaca-Blinder decomposition is that only the conditional means of a wage distribution, $E(Y|X)$, and its counterfactual can be compared. Recall that, in the Roy model described above, changes in the profitability of any occupation should result in the more efficient individuals self-selecting out of an occupation. The mean of a wage distribution is a poor instrument for observing this phenomenon: rather, any polarisation effect will be observed in the overall {\em distribution} of wages, $F_Y$. Ideally, we would like to compute a decomposition similar to \eqref{eq:odecomp}, but which decomposes changes in the $\alpha$th quantile of the wage distribution, $q_\tau(F_Y)$. Such a decomposition was considered by \citet{Firpo2011}; it is their technique, as described in \citet{Firpo2009}, that we apply here.

Under our decomposition, the wage of an individual $i$ is observed in one of two periods, $T=0$ or $T=1$. Under the hypothesis of wage polarisation, we will assume that individuals are paid under two distinct wage structures: the pre-polarisation wage structure that has distribution $F_{Y_0}$ (when $T=0$) and the post-polarisation wage structure, $F_{Y_1}$ (when $T=1$). We wish to compute an overall change $\Delta^\tau$ in the quantile statistic, attributable to changes in work force composition $\Delta^\tau_X$ and changes in the wage structure, $\Delta^\tau_S$:
\begin{align}
  \Delta^\tau_O &= q_\tau(F_{Y_1|T=1}) - q_\tau(F_{Y_0|T=0}) \notag \\
  &= \underbrace{q_\tau(F_{Y_1|T=1}) -  q_\tau(F_{Y_0|T=1})}_{\Delta^\alpha_S} + \underbrace{q_\tau(F_{Y_0|T=1}) - q_\tau(F_{Y_0|T=0})}_{\Delta^\alpha_X} \label{eq:decomp}
\end{align}Notice that this decomposition depends on the availability of a hypothetical counterfactual distribution, $F_{Y_0|T=1}$, wherein the workers of period $1$ are paid according to the wage structure of period~$0$. Although such a distribution cannot be directly observed, \citet{Firpo2011} show that a consistent estimator of $F_{Y_0|T=1}$ can be found by re-weighting $F_{Y_0}$ to have the same distribution as $F_{Y_1}$.

\citet{Firpo2009} demonstrate that the aggregate decomposition, as described in \eqref{eq:decomp}, can be performed using an OLS regression on the recentered influence function of the distributional statistic in question. The recentered influence function is the usual influence function used in the analysis of robust estimators, `recentered' by adding back the value of the distributional statistic. In the case of the quantile function $q_\tau$, the RIF is given by,
$$ RIF(y; q_\tau) = q_\tau + IF(y; q_\tau) = q_\tau + \frac{q_\tau - \mathbf{1}\{y \leq q_\tau\}}{f_Y(q_\tau)}. $$

Then the estimated coefficient $\gamma^{q_\tau}_t$ of an OLS regression of $RIF(y_t; q_\tau)$ on $X$ is
\begin{align*} 
\gamma^{q_\tau}_t &= (E[X \cdot X' | T = t])^{-1} \cdot E[RIF(y_t; q_\tau) \cdot X | T = t]
\intertext{\citet{Firpo2009} show that the distributional statistics themselves can be written as expectations of the conditional RIF, since the expected value of the influence function is zero, and thus $E[RIF(y_t;q_\tau)]=q_\tau$.}
q_\tau(F_t) &= E_X[E[RIF(y_t; q_\tau) | X=x]] = E[X|T=t] \cdot \gamma^{q_\tau}_t
\intertext{And thus we can write \eqref{eq:decomp} in a similar form as \eqref{eq:odecomp},}
\Delta^\alpha_O &= \underbrace{E[X|T=1] \cdot (\gamma^{q_\tau}_1 - \gamma^{q_\tau}_0)}_{\Delta^\alpha_S} + \underbrace{(E[X|T=1] - E[X|T=0]) \cdot \gamma^{q_\tau}_0}_{\Delta^\alpha_X}.
\end{align*}
Under the `ignorability' assumption, discussed below, both of these components of the decomposition are identified.

\subsection{Data Requirements for RIF-Regression} \label{sec:id}

One condition required for RIF-regression is that the support of covariates $X$ is the same for both time periods. In other words, it should not be possible to unambiguously predict which time period an observation belongs to, simply by observing the value of its covariates. 
\begin{assumption}[Overlapping support] \label{ass:overlap}
  Let the support of wage setting factors in both periods $[X',\epsilon']'$ be $\mathcal{X}\times\mathcal{E}$. For all $[x',e']' \in \mathcal{X}\times\mathcal{E}$,  $0 < \Pr[T=0 | X=x, \epsilon=e] < 1$.
\end{assumption}
Importantly, Assumption~\ref{ass:overlap} means that the set of occupational titles in both periods must be the same, even though many new types of occupational titles have been created since 1981-2. Despite to the small sample size, the data are only available at a two-digit level of aggregation, so that none of the occupations listed in the ANZSIC were missing a counterpart from 1981-2. A correspondence was easily found between two-digit ANZSIC groups and 1981-2 occupations, which were available at the three-digit level.

Further, in order to identify the explained and unexplained effects of the covariates, we require that the error term $\epsilon$ has the same conditional distribution in both time periods. This is known as the {\em ignorability} assumption.
\begin{assumption}[Ignorability]
  For $T\in\{0,1\}$, let $(T, X, \epsilon)$ have a joint distribution. Then, for all $x\in \mathcal{X}$, $\epsilon$ is independent of $T$ given $X=x$.
\end{assumption}

The assumptions stated so far are both plausible, and sufficient for identifying the wage structure component ($\hat{\Delta}_S$) and endowment effect component ($\hat{\Delta}_X$) of the aggregate decomposition. While this aggregate decomposition is useful, even more useful would be the ability to separate out the components of $\Delta_X$ or $\Delta_S$ into the contributions of each independent variable, the so-called `detailed decomposition'. 

\citep[p.27]{Fortin2011} show that non-parametric estimates of the detailed decomposition require assumptions that cannot be maintained in this context. For example,the following independence condition, found in \citet{Matzkin2003}, must hold:
\begin{assumption}[Independence]\label{ass:indep}
  For $T\in\{0,1\}$, $X$ is uncorrelated with $\epsilon$ in time $T$.
\end{assumption}
Most decompositions of the determinants of wages, including this one, follow the Mincerean `human capital' approach, which suggests that the primary determinants of wages are investments in education and experience, which enhance productivity \citep{Mincer1962}. For that reason, these covariates are included in $X$ in this study. However, as is well-known, OLS regression estimates of Mincer-style wage equations tend to exhibit endogeneity bias, since observable characteristics (such as years of schooling) tend to be correlated with unobserved characteristics such as general ability or talent \citep{Card1999}. Consequently, any regression specification that omits an accurate measure of `ability' will exhibit endogeneity bias, since the omitted variable will cause explanatory variables such as schooling to be correlated with the error term. That is to say, that the independence property is violated.

However, the impracticality of Assumption~\ref{ass:indep} is avoided by the linear functional form imposed by Assumption~\ref{ass:linear} \citep[p.28]{Fortin2011}. Furthermore, the linear functional form assumption allows for heteroskedasticity. This this application, this is a useful property, since income variance increases with educational attainment.

\subsection{Re-weighting the counterfactual distribution}\label{sec:reweight}

\citet[p.19]{Firpo2011} point out that the RIF-regression described above is a local approximation that may not hold for large variations in covariates $X$. In particular, if the relationship between $Y$ and $X$ is nonlinear, then shifts in the distribution of $X$ may result in different estimates for $\gamma^{q_\tau}_t$ even if $Y$ is invariant. 

Unfortunately, in this application, changes in covariates between period $T=0$ and $T=1$ cannot be assumed to be small. ABS data show that there are considerable differences in the composition of the labour force between 1981-2 and 2009-10 \citep{LFSApr2013}. The average unemployment rate in 1981-2 similar to that of 2009-10 (6.1 per cent versus 5.7 per cent, respectively), but the period was marked by considerable demographic changes. Since the 1980s, women have entered the work force in far greater numbers, and overall labour force participation patterns have varied. Between 1981-2 and 2009-10, the average participation rate for men fell from 77.7 per cent to 72.3 per cent. For women, on the other hand, the participation rate rose from 44.8 per cent to 58.6 per cent. And, for both sexes, the rate of part-time employment has increased dramatically. Clearly, the covariate distributions at both time periods are not directly comparable.

In order to create a comparable counterfactual wage distribution, \citet{Firpo2011} suggest a hybrid approach, where the data in period $0$ are reweighted so that covariates in period $0$ match those in period $1$. Adopting the re-weighting procedure suggested by \citet{DiNardo1996}, they aim to create a counterfactual wage distribution $F_{Y_0}^C$ that exhibits the characteristics of period $0$, but with the wage structure of period $1$:
\begin{align*}
  F_{Y_0}^C &= \int F_{Y_0|X_0}(y|X) dF_{X_1}(X)
\intertext{We now re-write this equation as an integral over $F_{X_0}(X)$, by adding a reweighting factor $\Psi(X) = dF_{X_1}(X)/dF_{X_0}(X)$:}
  F_{Y_0} &= \int F_{Y_0|X_0}(y|X) \Psi(X)dF_{X_0}(X)
\end{align*}
\citet{Fortin2011} show that this re-weighting factor, which is the ratio of two marginal distribution functions, can be manipulated with an application of Bayes' rule to yield a ratio of two binary outcome models:
\begin{align*}
  \label{eq:wt}
  \Psi(X) &= \frac{\Pr(T=1|X)/\Pr(T=1)}{\Pr(T=0|X)/\Pr(T=0)},
\end{align*}
that re-weights the data in period $0$ to match the distribution of covariates observed in period~$1$. To implement this re-weighting function, the probability of $T$ being 1 or 0 can be modeled using a probit model, fit to the combined data sets, with $T$ as the response variable. % Probit model: help! How do I weight this?

Using re-weighted data, we can estimate the means of the counterfactual distribution, $\hat{\bar{X}}=\sum_{i|T=0}\hat{\Psi}(X_i) \cdot X_i$, and the coefficients $\hat{\gamma}_{01}^{q_\tau}$ by regressing $RIF(Y_0;q_\tau)$ with the new sample weights. We then rewrite the decomposition \eqref{eq:decomp} as the sum of two separate Oaxaca-Blinder decompositions. The first term, the wage structure effect, is decomposed into a composition effect $\hat{\Delta}^{q_\tau}_{S,p}$ and specification error, $\hat{\Delta}^{q_\tau}_{S,e}$. The second gives a similar decomposition for composition effect:
\begin{align}
  \hat{\Delta}^{q_\tau} &= (\hat{\Delta}^{q_\tau}_{S,p} + \hat{\Delta}^{q_\tau}_{S,e}) + (\hat{\Delta}^{q_\tau}_{X,p} + \hat{\Delta}^{q_\tau}_{X,e}) \notag \\
  &= \underbrace{\left( [\bar{X}_{01} - \bar{X}_0 ] \hat{\gamma}^{q_\tau}_{01} +
    \bar{X}_{01}[\hat{\gamma}_{01}^{q_\tau} - \hat{\gamma}_0^{q_\tau}] \right)}_{\hat{\Delta}^{q_\tau}_{S}} +
  \underbrace{\left( \bar{X}_{1}[\hat{\gamma}_{1}^{q_\tau} - \hat{\gamma}_{01}^{q_\tau}] + 
    [\bar{X}_{1} - \bar{X}_{01} ] \hat{\gamma}^{q_\tau}_{01}\right)}_{\hat{\Delta}^{q_\tau}_{X}}.
\end{align}

This decomposition can be performed on income surveys of repeated cross-sections of the same markets over time.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
